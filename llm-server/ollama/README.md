# LLM server - Ollama Instance

Simple Docker-based server to host an Ollama LLM instance for local or networked use.